{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23R0Z9RojXYW"
   },
   "source": [
    "# Week 2 Assignment: Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfSQ-kX-MLEr"
   },
   "source": [
    "For this week's assignment, you will build a data pipeline using using [Tensorflow Extended (TFX)](https://www.tensorflow.org/tfx) to prepare features from the [Metro Interstate Traffic Volume dataset](https://archive.ics.uci.edu/ml/datasets/Metro+Interstate+Traffic+Volume). Try to only use the documentation and code hints to accomplish the tasks but feel free to review the 2nd ungraded lab this week in case you get stuck.\n",
    "\n",
    "Upon completion, you will have:\n",
    "\n",
    "* created an InteractiveContext to run TFX components interactively\n",
    "* used TFX ExampleGen component to split your dataset into training and evaluation datasets\n",
    "* generated the statistics and the schema of your dataset using TFX StatisticsGen and SchemaGen components\n",
    "* validated the evaluation dataset statistics using TFX ExampleValidator\n",
    "* performed feature engineering using the TFX Transform component\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [1 - Setup](#1)\n",
    "  - [1.1 - Imports](#1-1)\n",
    "  - [1.2 - Define Paths](#1-2)\n",
    "  - [1.3 - Preview the Dataset](#1-3)\n",
    "  - [1.4 - Create the InteractiveContext](#1-4)\n",
    "- [2 - Run TFX components interactively](#2)\n",
    "  - [2.1 - ExampleGen](#2-1)\n",
    "    - [Exercise 1 - ExampleGen](#ex-1)\n",
    "    - [Exercise 2 - get_records()](#ex-2)\n",
    "  - [2.2 - StatisticsGen](#2-2)\n",
    "    - [Exercise 3 - StatisticsGen](#ex-3)\n",
    "  - [2.3 - SchemaGen](#2-3)\n",
    "    - [Exercise 4 - SchemaGen](#ex-4)\n",
    "  - [2.4 - ExampleValidator](#2-4)\n",
    "    - [Exercise 5 - ExampleValidator](#ex-5)\n",
    "  - [2.5 - Transform](#2-5)\n",
    "    - [Exercise 6 - preprocessing_fn()](#ex-6)\n",
    "    - [Exercise 7 - Transform](#ex-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GivNBNYjb3b"
   },
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Setup\n",
    "As usual, you will first need to import the necessary packages. For reference, the lab environment uses *TensorFlow version: 2.3.1* and *TFX version: 0.24.0*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-ePgV0Lj68Q"
   },
   "source": [
    "<a name='1-1'></a>\n",
    "### 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YIqpWK9efviJ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tfx.components import CsvExampleGen\n",
    "from tfx.components import ExampleValidator\n",
    "from tfx.components import SchemaGen\n",
    "from tfx.components import StatisticsGen\n",
    "from tfx.components import Transform\n",
    "\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1-2'></a>\n",
    "### 1.2 - Define paths\n",
    "\n",
    "You will define a few global variables to indicate paths in the local workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of the pipeline metadata store\n",
    "_pipeline_root = 'metro_traffic_pipeline/'\n",
    "\n",
    "# directory of the raw data files\n",
    "_data_root = 'metro_traffic_pipeline/data'\n",
    "\n",
    "# path to the raw training data\n",
    "_data_filepath = os.path.join(_data_root, 'metro_traffic_volume.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2cMMAbSkGfX"
   },
   "source": [
    "<a name='1-3'></a>\n",
    "### 1.3 - Preview the  dataset\n",
    "\n",
    "The [Metro Interstate Traffic Volume dataset](https://archive.ics.uci.edu/ml/datasets/Metro+Interstate+Traffic+Volume) contains hourly traffic volume of a road in Minnesota from 2012-2018. With this data, you can develop a model for predicting the traffic volume given the date, time, and weather conditions. The attributes are:\n",
    "\n",
    "* **holiday** - US National holidays plus regional holiday, Minnesota State Fair\n",
    "* **temp** - Average temp in Kelvin\n",
    "* **rain_1h** - Amount in mm of rain that occurred in the hour\n",
    "* **snow_1h** - Amount in mm of snow that occurred in the hour\n",
    "* **clouds_all** - Percentage of cloud cover\n",
    "* **weather_main** - Short textual description of the current weather\n",
    "* **weather_description** - Longer textual description of the current weather\n",
    "* **date_time** - DateTime Hour of the data collected in local CST time\n",
    "* **traffic_volume** - Numeric Hourly I-94 ATR 301 reported westbound traffic volume\n",
    "* **month** - taken from date_time\n",
    "* **day** - taken from date_time\n",
    "* **day_of_week** - taken from date_time\n",
    "* **hour** - taken from date_time\n",
    "\n",
    "\n",
    "*Disclaimer: We added the last four attributes shown above (i.e. month, day, day_of_week, hour) to the original dataset to increase the features you can transform later.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blZC1sIQOWfH"
   },
   "source": [
    "Take a quick look at the first few rows of the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c5YPeLPFOXaD"
   },
   "outputs": [],
   "source": [
    "# Preview the dataset\n",
    "!head {_data_filepath}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ONIE_hdkPS4"
   },
   "source": [
    "<a name='1-4'></a>\n",
    "### 1.4 - Create the InteractiveContext\n",
    "\n",
    "You will need to initialize the `InteractiveContext` to enable running the TFX components interactively. As before, you will let it create the metadata store in the `_pipeline_root` directory. You can safely ignore the warning about the missing metadata config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Rh6K5sUf9dd"
   },
   "outputs": [],
   "source": [
    "# Declare the InteractiveContext and use a local sqlite file as the metadata store.\n",
    "# You can ignore the warning about the missing metadata config file\n",
    "context = InteractiveContext(pipeline_root=_pipeline_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdQWxfsVkzdJ"
   },
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Run TFX components interactively\n",
    "\n",
    "In the following exercises, you will create the data pipeline components one-by-one, run each of them, and visualize their output artifacts. Recall that we refer to the outputs of pipeline components as *artifacts* and these can be inputs to the next stage of the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9fwt9gQk3BR"
   },
   "source": [
    "<a name='2-1'></a>\n",
    "### 2.1 - ExampleGen\n",
    "\n",
    "The pipeline starts with the [ExampleGen](https://www.tensorflow.org/tfx/guide/examplegen) component. It will:\n",
    "\n",
    "*   split the data into training and evaluation sets (by default: 2/3 train, 1/3 eval).\n",
    "*   convert each data row into `tf.train.Example` format. This [protocol buffer](https://developers.google.com/protocol-buffers) is designed for Tensorflow operations and is used by the TFX components.\n",
    "*   compress and save the data collection under the `_pipeline_root` directory for other components to access. These examples are stored in `TFRecord` format. This optimizes read and write operations within Tensorflow especially if you have a large collection of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-1'></a>\n",
    "#### Exercise 1: ExampleGen\n",
    "\n",
    "Fill out the code below to ingest the data from the CSV file stored in the `_data_root` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyXjuMt8f-9u"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE\n",
    "\n",
    "# Instantiate ExampleGen with the input CSV dataset\n",
    "example_gen = None\n",
    "\n",
    "# Run the component using the InteractiveContext instance\n",
    "None\n",
    "\n",
    "### END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqCoZh7KPUm9"
   },
   "source": [
    "You should see the output cell of the `InteractiveContext` above showing the metadata associated with the component execution. You can expand the items under `.component.outputs` and see that an `Examples` artifact for the train and eval split is created in `metro_traffic_pipeline/CsvExampleGen/examples/{execution_id}`. \n",
    "\n",
    "You can also check that programmatically with the following snippet. You can focus on the `try` block. The `except` and `else` block is needed mainly for grading. `context.run()` yields no operation when executed in a non-interactive environment (such as the grader script that runs outside of this notebook). In such scenarios, the URI must be manually set to avoid errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "880KkTAkPeUg"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # get the artifact object\n",
    "    artifact = example_gen.outputs['examples'].get()[0]\n",
    "    \n",
    "    # print split names and uri\n",
    "    print(f'split names: {artifact.split_names}')\n",
    "    print(f'artifact uri: {artifact.uri}')\n",
    "\n",
    "# for grading since context.run() does not work outside the notebook\n",
    "except IndexError:\n",
    "    print(\"context.run() was no-op\")\n",
    "    examples_path = './metro_traffic_pipeline/CsvExampleGen/examples'\n",
    "    dir_id = os.listdir(examples_path)[0]\n",
    "    artifact_uri = f'{examples_path}/{dir_id}'\n",
    "\n",
    "else:\n",
    "    artifact_uri = artifact.uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6vcbW_wPqvl"
   },
   "source": [
    "The ingested data has been saved to the directory specified by the artifact Uniform Resource Identifier (URI). As a sanity check, you can take a look at some of the training examples. This requires working with Tensorflow data types, particularly `tf.train.Example` and `TFRecord` (you can read more about them [here](https://www.tensorflow.org/tutorials/load_data/tfrecord)). Let's first load the `TFRecord` into a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H4XIXjiCPwzQ"
   },
   "outputs": [],
   "source": [
    "# Get the URI of the output artifact representing the training examples, which is a directory\n",
    "train_uri = os.path.join(artifact_uri, 'train')\n",
    "\n",
    "# Get the list of files in this directory (all compressed TFRecord files)\n",
    "tfrecord_filenames = [os.path.join(train_uri, name)\n",
    "                      for name in os.listdir(train_uri)]\n",
    "\n",
    "# Create a `TFRecordDataset` to read these files\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-2'></a>\n",
    "#### Exercise 2: get_records()\n",
    "\n",
    "Complete the helper function below to return a specified number of examples.\n",
    "\n",
    "*Hints: You may find the [MessageToDict](https://googleapis.dev/python/protobuf/latest/google/protobuf/json_format.html#google.protobuf.json_format.MessageToDict) helper function and tf.train.Example's [ParseFromString()](https://googleapis.dev/python/protobuf/latest/google/protobuf/message.html#google.protobuf.message.Message.ParseFromString) method useful here. You can also refer [here](https://www.tensorflow.org/tutorials/load_data/tfrecord) for a refresher on TFRecord and tf.train.Example()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_records(dataset, num_records):\n",
    "    '''Extracts records from the given dataset.\n",
    "    Args:\n",
    "        dataset (TFRecordDataset): dataset saved by ExampleGen\n",
    "        num_records (int): number of records to preview\n",
    "    '''\n",
    "    \n",
    "    # initialize an empty list\n",
    "    records = []\n",
    "\n",
    "    ### START CODE HERE\n",
    "    # Use the `take()` method to specify how many records to get\n",
    "    for tfrecord in dataset.take(num_records):\n",
    "        \n",
    "        # Get the numpy property of the tensor\n",
    "        serialized_example = None\n",
    "        \n",
    "        # Initialize a `tf.train.Example()` to read the serialized data\n",
    "        example = None\n",
    "        \n",
    "        # Read the example data (output is a protocol buffer message)\n",
    "        None\n",
    "        \n",
    "        # convert the protocol bufffer message to a Python dictionary\n",
    "        example_dict = None\n",
    "        \n",
    "        # append to the records list\n",
    "        None\n",
    "        \n",
    "    ### END CODE HERE\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 3 records from the dataset\n",
    "sample_records = get_records(dataset, 3)\n",
    "\n",
    "# Print the output\n",
    "pp.pprint(sample_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gluYjccf-IP"
   },
   "source": [
    "You should see three of the examples printed above. Now that `ExampleGen` has finished ingesting the data, the next step is data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csM6BFhtk5Aa"
   },
   "source": [
    "<a name='2-2'></a>\n",
    "### 2.2 - StatisticsGen\n",
    "The [StatisticsGen](https://www.tensorflow.org/tfx/guide/statsgen) component computes statistics over your dataset for data analysis, as well as for use in downstream components. It uses the [TensorFlow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started) library.\n",
    "\n",
    "`StatisticsGen` takes as input the dataset ingested using `CsvExampleGen`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-3'></a>\n",
    "#### Exercise 3: StatisticsGen\n",
    "\n",
    "Fill the code below to generate statistics from the output examples of `CsvExampleGen`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MAscCCYWgA-9"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE\n",
    "# Instantiate StatisticsGen with the ExampleGen ingested dataset\n",
    "statistics_gen = None\n",
    "    \n",
    "\n",
    "# Run the component\n",
    "None\n",
    "### END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the statistics generated\n",
    "context.show(statistics_gen.outputs['statistics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLKLTO9Nk60p"
   },
   "source": [
    "<a name='2-3'></a>\n",
    "### 2.3 - SchemaGen\n",
    "\n",
    "The [SchemaGen](https://www.tensorflow.org/tfx/guide/schemagen) component also uses TFDV to generate a schema based on your data statistics. As you've learned previously, a schema defines the expected bounds, types, and properties of the features in your dataset.\n",
    "\n",
    "`SchemaGen` will take as input the statistics that we generated with `StatisticsGen`, looking at the training split by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-4'></a>\n",
    "#### Exercise 4: SchemaGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ygQvZ6hsiQ_J"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE\n",
    "# Instantiate SchemaGen with the output statistics from the StatisticsGen\n",
    "schema_gen = None\n",
    "    \n",
    "    \n",
    "\n",
    "# Run the component\n",
    "None\n",
    "### END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zi6TxTUKXM6b"
   },
   "source": [
    "If all went well, you can now visualize the generated schema as a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ec9vqDXpXeMb"
   },
   "outputs": [],
   "source": [
    "# Visualize the output\n",
    "context.show(schema_gen.outputs['schema'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZWWdbA-m7zp"
   },
   "source": [
    "Each attribute in your dataset shows up as a row in the schema table, alongside its properties. The schema also captures all the values that a categorical feature takes on, denoted as its domain.\n",
    "\n",
    "This schema will be used to detect anomalies in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1qcUuO9k9f8"
   },
   "source": [
    "<a name='2-4'></a>\n",
    "### 2.4 - ExampleValidator\n",
    "\n",
    "The [ExampleValidator](https://www.tensorflow.org/tfx/guide/exampleval) component detects anomalies in your data based on the generated schema from the previous step. Like the previous two components, it also uses TFDV under the hood. \n",
    "\n",
    "`ExampleValidator` will take as input the statistics from `StatisticsGen` and the schema from `SchemaGen`. By default, it compares the statistics from the evaluation split to the schema from the training split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2-4'></a>\n",
    "#### Exercise 5: ExampleValidator\n",
    "\n",
    "Fill the code below to detect anomalies in your datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRlRUuGgiXks"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE\n",
    "# Instantiate ExampleValidator with the statistics and schema from the previous steps\n",
    "example_validator = None\n",
    "    \n",
    "    \n",
    "\n",
    "# Run the component\n",
    "None\n",
    "### END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "855mrHgJcoer"
   },
   "source": [
    "As with the previous steps, you can visualize the anomalies as a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TDyAAozQcrk3"
   },
   "outputs": [],
   "source": [
    "# Visualize the output\n",
    "context.show(example_validator.outputs['anomalies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znMoJj60ybZx"
   },
   "source": [
    "If there are anomalies detected, you should examine how you should handle it. For example, you can relax distribution constraints or modify the domain of some features. You've had some practice with this last week when you used TFDV and you can also do that here. \n",
    "\n",
    "For this particular case, there should be no anomalies detected and we can proceed to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPViEz5RlA36"
   },
   "source": [
    "<a name='2-5'></a>\n",
    "### 2.5 - Transform\n",
    "\n",
    "In this section, you will use the [Transform](https://www.tensorflow.org/tfx/guide/transform) component to perform feature engineering.\n",
    "\n",
    "`Transform` will take as input the data from `ExampleGen`, the schema from `SchemaGen`, as well as a module containing the preprocessing function.\n",
    "\n",
    "The component expects an external module for your Transform code so you need to use the magic command `%% writefile` to save the file to disk. We have defined a few constants that group the data's attributes according to the transforms you will perform later. This file will also be saved locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PuNSiUKb4YJf"
   },
   "outputs": [],
   "source": [
    "# Set the constants module filename\n",
    "_traffic_constants_module_file = 'traffic_constants.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HPjhXuIF4YJh"
   },
   "outputs": [],
   "source": [
    "%%writefile {_traffic_constants_module_file}\n",
    "\n",
    "# Features to be scaled to the z-score\n",
    "DENSE_FLOAT_FEATURE_KEYS = ['temp', 'snow_1h']\n",
    "\n",
    "# Features to bucketize\n",
    "BUCKET_FEATURE_KEYS = ['rain_1h']\n",
    "\n",
    "# Number of buckets used by tf.transform for encoding each feature.\n",
    "FEATURE_BUCKET_COUNT = {'rain_1h': 3}\n",
    "\n",
    "# Feature to scale from 0 to 1\n",
    "RANGE_FEATURE_KEYS = ['clouds_all']\n",
    "\n",
    "# Number of vocabulary terms used for encoding VOCAB_FEATURES by tf.transform\n",
    "VOCAB_SIZE = 1000\n",
    "\n",
    "# Count of out-of-vocab buckets in which unrecognized VOCAB_FEATURES are hashed.\n",
    "OOV_SIZE = 10\n",
    "\n",
    "# Features with string data types that will be converted to indices\n",
    "VOCAB_FEATURE_KEYS = [\n",
    "    'holiday',\n",
    "    'weather_main',\n",
    "    'weather_description'\n",
    "]\n",
    "\n",
    "# Features with int data type that will be kept as is\n",
    "CATEGORICAL_FEATURE_KEYS = [\n",
    "    'hour', 'day', 'day_of_week', 'month'\n",
    "]\n",
    "\n",
    "# Feature to predict\n",
    "VOLUME_KEY = 'traffic_volume'\n",
    "\n",
    "def transformed_name(key):\n",
    "    return key + '_xf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-6'></a>\n",
    "#### Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Duj2Ax5z4YJl"
   },
   "source": [
    "Next, you will fill out the transform module. As mentioned, this will also be saved to disk. Specifically, you will complete the `preprocessing_fn` which defines the transformations. See the code comments for instructions and refer to the [tft module documentation](https://www.tensorflow.org/tfx/transform/api_docs/python/tft) to look up which function to use for a given group of keys.\n",
    "\n",
    "For the label (i.e. `VOLUME_KEY`), you will transform it to indicate if it is greater than the mean of the entire dataset. For the transform to work, you will need to convert a [SparseTensor](https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor) to a dense one. We've provided a `_fill_in_missing()` helper function for you to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4AJ9hBs94YJm"
   },
   "outputs": [],
   "source": [
    "# Set the transform module filename\n",
    "_traffic_transform_module_file = 'traffic_transform.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graded": true,
    "id": "MYmxxx9A4YJn",
    "name": "preprocessing_fn_code"
   },
   "outputs": [],
   "source": [
    "%%writefile {_traffic_transform_module_file}\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "\n",
    "import traffic_constants\n",
    "\n",
    "# Unpack the contents of the constants module\n",
    "_DENSE_FLOAT_FEATURE_KEYS = traffic_constants.DENSE_FLOAT_FEATURE_KEYS\n",
    "_RANGE_FEATURE_KEYS = traffic_constants.RANGE_FEATURE_KEYS\n",
    "_VOCAB_FEATURE_KEYS = traffic_constants.VOCAB_FEATURE_KEYS\n",
    "_VOCAB_SIZE = traffic_constants.VOCAB_SIZE\n",
    "_OOV_SIZE = traffic_constants.OOV_SIZE\n",
    "_CATEGORICAL_FEATURE_KEYS = traffic_constants.CATEGORICAL_FEATURE_KEYS\n",
    "_BUCKET_FEATURE_KEYS = traffic_constants.BUCKET_FEATURE_KEYS\n",
    "_FEATURE_BUCKET_COUNT = traffic_constants.FEATURE_BUCKET_COUNT\n",
    "_VOLUME_KEY = traffic_constants.VOLUME_KEY\n",
    "_transformed_name = traffic_constants.transformed_name\n",
    "\n",
    "\n",
    "def preprocessing_fn(inputs):\n",
    "    \"\"\"tf.transform's callback function for preprocessing inputs.\n",
    "    Args:\n",
    "    inputs: map from feature keys to raw not-yet-transformed features.\n",
    "    Returns:\n",
    "    Map from string feature key to transformed feature operations.\n",
    "    \"\"\"\n",
    "    outputs = {}\n",
    "\n",
    "    ### START CODE HERE\n",
    "    \n",
    "    # Scale these features to the z-score.\n",
    "    for key in _DENSE_FLOAT_FEATURE_KEYS:\n",
    "        # Scale these features to the z-score.\n",
    "        outputs[_transformed_name(key)] = None\n",
    "            \n",
    "\n",
    "    # Scale these feature/s from 0 to 1\n",
    "    for key in _RANGE_FEATURE_KEYS:\n",
    "        outputs[_transformed_name(key)] = None\n",
    "            \n",
    "\n",
    "    # Transform the strings into indices \n",
    "    # hint: use the VOCAB_SIZE and OOV_SIZE to define the top_k and num_oov parameters\n",
    "    for key in _VOCAB_FEATURE_KEYS:\n",
    "        outputs[_transformed_name(key)] = None\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "    # Bucketize the feature\n",
    "    for key in _BUCKET_FEATURE_KEYS:\n",
    "        outputs[_transformed_name(key)] = None\n",
    "            \n",
    "            \n",
    "\n",
    "    # Keep as is. No tft function needed.\n",
    "    for key in _CATEGORICAL_FEATURE_KEYS:\n",
    "        outputs[_transformed_name(key)] = None\n",
    "\n",
    "        \n",
    "    # Use `tf.cast` to cast the label key to float32 and fill in the missing values.\n",
    "    traffic_volume = None\n",
    "  \n",
    "    \n",
    "    # Create a feature that shows if the traffic volume is greater than the mean and cast to an int\n",
    "    outputs[_transformed_name(_VOLUME_KEY)] = tf.cast(  \n",
    "        \n",
    "        # Use `tf.greater` to check if the traffic volume in a row is greater than the mean of the entire traffic volumn column\n",
    "        tf.greater(None, None(tf.cast(inputs[_VOLUME_KEY], tf.float32))),\n",
    "        \n",
    "        tf.int64)                                        \n",
    "\n",
    "    ### END CODE HERE\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def _fill_in_missing(x):\n",
    "    \"\"\"Replace missing values in a SparseTensor and convert to a dense tensor.\n",
    "    Fills in missing values of `x` with '' or 0, and converts to a dense tensor.\n",
    "    Args:\n",
    "        x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n",
    "          in the second dimension.\n",
    "    Returns:\n",
    "        A rank 1 tensor where missing values of `x` have been filled in.\n",
    "    \"\"\"\n",
    "    default_value = '' if x.dtype == tf.string else 0\n",
    "    \n",
    "    return tf.squeeze(\n",
    "      tf.sparse.to_dense(\n",
    "          tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n",
    "          default_value),\n",
    "      axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-7'></a>\n",
    "#### Exercise 7\n",
    "\n",
    "With the transform module defined, complete the code below to perform feature engineering on the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jHfhth_GiZI9"
   },
   "outputs": [],
   "source": [
    "# ignore tf warning messages\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "\n",
    "### START CODE HERE\n",
    "# Instantiate the Transform component\n",
    "transform = None\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# Run the component\n",
    "None\n",
    "### END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwAwb4rARRQ2"
   },
   "source": [
    "You should see the output cell by `InteractiveContext` above and see the three artifacts in `.component.outputs`:\n",
    "\n",
    "* `transform_graph` is the graph that performs the preprocessing operations. This will be included during training and serving to ensure consistent transformations of incoming data.\n",
    "* `transformed_examples` points to the preprocessed training and evaluation data.\n",
    "* `updated_analyzer_cache` are stored calculations from previous runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyFkBd9AR1sy"
   },
   "source": [
    "The `transform_graph` artifact URI should point to a directory containing:\n",
    "\n",
    "* The `metadata` subdirectory containing the schema of the original data.\n",
    "* The `transformed_metadata` subdirectory containing the schema of the preprocessed data. \n",
    "* The `transform_fn` subdirectory containing the actual preprocessing graph.\n",
    "\n",
    "Again, for grading purposes, we inserted an `except` and `else` below to handle checking the output outside the notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5tRw4DneR3i7"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Get the uri of the transform graph\n",
    "    transform_graph_uri = transform.outputs['transform_graph'].get()[0].uri\n",
    "\n",
    "except IndexError:\n",
    "    print(\"context.run() was no-op\")\n",
    "    transform_path = './metro_traffic_pipeline/Transform/transformed_examples'\n",
    "    dir_id = os.listdir(transform_path)[0]\n",
    "    transform_graph_uri = f'{transform_path}/{dir_id}'\n",
    "    \n",
    "else:\n",
    "    # List the subdirectories under the uri\n",
    "    os.listdir(transform_graph_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, you can also take a look at a few of the transformed examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Get the URI of the output artifact representing the transformed examples\n",
    "    train_uri = os.path.join(transform.outputs['transformed_examples'].get()[0].uri, 'train')\n",
    "    \n",
    "except IndexError:\n",
    "    print(\"context.run() was no-op\")\n",
    "    train_uri = os.path.join(transform_graph_uri, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pwbW2zPKR_S4"
   },
   "outputs": [],
   "source": [
    "# Get the list of files in this directory (all compressed TFRecord files)\n",
    "tfrecord_filenames = [os.path.join(train_uri, name)\n",
    "                      for name in os.listdir(train_uri)]\n",
    "\n",
    "# Create a `TFRecordDataset` to read these files\n",
    "transformed_dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mSDZ2rJC7NQW"
   },
   "outputs": [],
   "source": [
    "# Get 3 records from the dataset\n",
    "sample_records_xf = get_records(transformed_dataset, 3)\n",
    "\n",
    "# Print the output\n",
    "pp.pprint(sample_records_xf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations on completing this week's assignment!** You've just demonstrated how to build a data pipeline and do feature engineering. You will build upon these concepts in the next weeks where you will deal with more complex datasets and also access the metadata store. Keep up the good work!"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "MLEPC2W2-1",
    "MLEPC2W2-2",
    "MLEPC2W2-3",
    "MLEPC2W2-4",
    "MLEPC2W2-5",
    "MLEPC2W2-6",
    "MLEPC2W2-7"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
